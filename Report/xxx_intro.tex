Transfer learning is the method of reusing trained models on different tasks. Convolutional networks learn their features. Thus by training deep convolutional networks on large-scale datasets, we can train features that can be applied to other datasets. We apply a trained deep network to a relatively smaller dataset, retrain the classification layers and show the effectiveness of such approach.

In CNN model trained for image classification, the first convolution layer basically picks simple, local geometry features from input images(corners, lines, sketches), whereas higher-level convolution layers tend to extract semantic informations in wider receptive field(objects components). We visualized the first convolution layer and last convolution layer outputs, also the filter weights from the first convolution layer. This also implies depth of the neural network plays an important part in image classfication problem. Hence we designed feature extraction experiment in the last to show the significant degeneracy of classification ability after removing last several convolutional blocks of a classical CNN model VGG16.